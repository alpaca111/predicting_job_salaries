{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : collecting data\n",
    "## Webscraping Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.indeed.co.uk/data-scientist-jobs-in-London'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining scraping functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract Jobtitle function\n",
    "def extract_jobtitle_from_result(soup):\n",
    "    jobtitle_list = []\n",
    "    for element in soup.findAll('div', {'class': 'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "        try:\n",
    "            jobtitle_list.append(element.find('a', {'class': 'jobtitle turnstileLink'}).text.strip('\\n'))\n",
    "        except:\n",
    "            jobtitle_list.append('None')\n",
    "    return jobtitle_list\n",
    "\n",
    "#extract Company function\n",
    "def extract_company_from_result(soup):\n",
    "    company_list = []\n",
    "    for element in soup.findAll('div', {'class': 'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "        try:\n",
    "            company_list.append(element.find('span', {'class': 'company'}).text.strip('\\n'))\n",
    "        except:\n",
    "            try:\n",
    "                company_list.append(element.find('a', {'class': 'turnstileLink'}).text.strip('\\n'))\n",
    "\n",
    "            except:\n",
    "                company_list.append('None') \n",
    "    return company_list\n",
    "\n",
    "#extract salary function\n",
    "def extract_salary_from_result(soup):\n",
    "    salary_list = []\n",
    "    for element in soup.findAll('div', {'class': 'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "        try:\n",
    "            salary_list.append(element.find('span', {'class': 'salaryText'}).text.strip('\\n'))\n",
    "        except:\n",
    "            salary_list.append('None') #fill missing entries with 'None'  \n",
    "    return salary_list\n",
    "\n",
    "#extract Location function\n",
    "def extract_location_from_result(soup):\n",
    "    location_list = []\n",
    "    for element in soup.findAll('div', {'class': 'jobsearch-SerpJobCard unifiedRow row result'}):\n",
    "        try:\n",
    "            location_list.append(element.find('span', {'class': 'location accessible-contrast-color-location'}).text.strip('\\n'))\n",
    "        except:\n",
    "            try:\n",
    "                location_list.append(element.find('div', {'class': 'location accessible-contrast-color-location'}).text.strip('\\n'))\n",
    "            except:\n",
    "                location_list.append('None')                \n",
    "    return location_list \n",
    "#Max number of results calculator \n",
    "def max_iter_calc(city):\n",
    "    URL = 'https://www.indeed.co.uk/jobs?q=data+scientist,+data+analyst,+machine+learning,+Data+Architect,+data+engineer&l={}&start=0'.format(city)\n",
    "    r = requests.get(URL) \n",
    "    soup = BeautifulSoup(r.text, 'html.parser') \n",
    "    raw_page_range = soup.find('div', {'class': 'searchCount-a11y-contrast-color'}).text.split('\\n')[2].split()\n",
    "    \n",
    "    page_range = []    \n",
    "    for word in raw_page_range:\n",
    "        if word.replace(',', '').isdigit():\n",
    "            page_range.append(int(word.replace(',', '')))\n",
    "\n",
    "    max_result = page_range[1]\n",
    "    max_n_pages = round(max_result/15)\n",
    "    max_results_per_city = max_n_pages*10\n",
    "    \n",
    "    if max_results_per_city > 800:\n",
    "        return 800\n",
    "    else:\n",
    "        return max_results_per_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For one City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 "
     ]
    }
   ],
   "source": [
    "import time \n",
    "max_results_per_city =850  #no need to go past 1000 as final page for London goes to ~500\n",
    "raw_data = []\n",
    "\n",
    "for start in range(0, max_results_per_city, 10): #iterate over different URL's with different starting points\n",
    "    URL = 'https://www.indeed.co.uk/jobs?q=data+scientist,+data+analyst,+machine+learning,+Data+Architect,+data+engineer&l={}&start={}'.format(city,start)\n",
    "    r = requests.get(URL)         #URL chose with 'data scientist, data analyst, machine learning' in search\n",
    "    soup = BeautifulSoup(r.text, 'html.parser') #for each URL get the raw text\n",
    "    raw_data.append(soup)  #append the raw text into raw_data list\n",
    "    print(start, end=' ')  #display how far into the process this loop is (horizontally printed)\n",
    "    time.sleep(np.abs(np.random.normal(loc=5,scale=0.5)))  #add sleeper delay to avoid captcha block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst Apprentice', 'Data Analyst (FinOps)', 'Data Analyst Financial Services (Graduate Role)', 'Data Analyst', 'Machine Learning Research Scientist']\n",
      "['TalentCloud Solutions', 'Funding Circle UK', 'Tardis Group', 'Exchange Data International', 'nPlan']\n",
      "['£20,000 a year', 'None', '£25,000 - £32,500 a year', '£25,000 a year', 'None']\n",
      "['London N5 1XL', 'London', 'London EC2V', 'London NW5 1JY', 'London']\n"
     ]
    }
   ],
   "source": [
    "#results \n",
    "import itertools\n",
    "\n",
    "jobtitle_listoflist = []\n",
    "company_listoflist = []\n",
    "salary_listoflist = []\n",
    "location_listoflist = []\n",
    "\n",
    "for clickcard in raw_data:  #collect each clickard within raw_data\n",
    "    jobtitle_listoflist.append(extract_jobtitle_from_result(clickcard))\n",
    "    company_listoflist.append(extract_company_from_result(clickcard))\n",
    "    salary_listoflist.append(extract_salary_from_result(clickcard))\n",
    "    location_listoflist.append(extract_location_from_result(clickcard))\n",
    "         \n",
    "jobtitle_list = list(itertools.chain(*jobtitle_listoflist)) #convert list of lists into single list using itertools\n",
    "company_list = list(itertools.chain(*company_listoflist))\n",
    "salary_list = list(itertools.chain(*salary_listoflist))\n",
    "location_list = list(itertools.chain(*location_listoflist))\n",
    "\n",
    "print(jobtitle_list[0:5])\n",
    "print(company_list[0:5])\n",
    "print(salary_list[0:5])\n",
    "print(location_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Apprentice</td>\n",
       "      <td>TalentCloud Solutions</td>\n",
       "      <td>£20,000 a year</td>\n",
       "      <td>London N5 1XL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst (FinOps)</td>\n",
       "      <td>Funding Circle UK</td>\n",
       "      <td>None</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst Financial Services (Graduate Role)</td>\n",
       "      <td>Tardis Group</td>\n",
       "      <td>£25,000 - £32,500 a year</td>\n",
       "      <td>London EC2V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Exchange Data International</td>\n",
       "      <td>£25,000 a year</td>\n",
       "      <td>London NW5 1JY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Research Scientist</td>\n",
       "      <td>nPlan</td>\n",
       "      <td>None</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          jobtitle  \\\n",
       "0                          Data Analyst Apprentice   \n",
       "1                            Data Analyst (FinOps)   \n",
       "2  Data Analyst Financial Services (Graduate Role)   \n",
       "3                                     Data Analyst   \n",
       "4              Machine Learning Research Scientist   \n",
       "\n",
       "                       company                    salary        location  \n",
       "0        TalentCloud Solutions            £20,000 a year   London N5 1XL  \n",
       "1            Funding Circle UK                      None          London  \n",
       "2                 Tardis Group  £25,000 - £32,500 a year     London EC2V  \n",
       "3  Exchange Data International            £25,000 a year  London NW5 1JY  \n",
       "4                        nPlan                      None          London  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for London scrape\n",
    "raw_df_london = pd.DataFrame({'jobtitle': jobtitle_list, 'company': company_list, \n",
    "                              'salary': salary_list, 'location': location_list}) \n",
    "raw_df_london = raw_df_london.copy()\n",
    "raw_df_london.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For multiple cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london\n",
      "Max n. of results per city:  800\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 manchester\n",
      "Max n. of results per city:  800\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 500 510 520 530 540 550 560 570 580 590 600 610 620 630 640 650 660 670 680 690 700 710 720 730 740 750 760 770 780 790 birmingham\n",
      "Max n. of results per city:  500\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 leeds\n",
      "Max n. of results per city:  430\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 glasgow\n",
      "Max n. of results per city:  260\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 southampton\n",
      "Max n. of results per city:  250\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 liverpool\n",
      "Max n. of results per city:  280\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 newcastle\n",
      "Max n. of results per city:  140\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 "
     ]
    }
   ],
   "source": [
    "import time \n",
    "import itertools\n",
    "\n",
    "city_list = ['london','manchester','birmingham', 'leeds','glasgow','southampton','liverpool','newcastle']\n",
    "\n",
    "dict_of_city_dfs = {}      #creating empty dict - accumulates raw df's after completed for each city\n",
    "\n",
    "for city in city_list: #iterates over list of cities\n",
    "    print(city) # city status\n",
    "    \n",
    "    max_results_per_city = max_iter_calc(city) #calls the max number of iterations calculator for given city\n",
    "    print(\"Max n. of results per city: \", max_results_per_city)\n",
    "    time.sleep(np.abs(np.random.normal(loc=6,scale=0.5)))  #add sleeper delay to avoid captcha block\n",
    "\n",
    "    raw_data = [] #list of raw clickards\n",
    "    \n",
    "    for start in range(0, max_results_per_city, 10): #iterate over different URL's with different starting points\n",
    "        URL = 'https://www.indeed.co.uk/jobs?q=data+scientist,+data+analyst,+machine+learning,+Data+Architect,+data+engineer&l={}&start={}'.format(city,start)\n",
    "        r = requests.get(URL)         #URL chose with 'data scientist/analyst/engineer/architect, machine learning' in searchbar\n",
    "        soup = BeautifulSoup(r.text, 'html.parser') #for each URL get the raw text\n",
    "        raw_data.append(soup)  #append the raw text into raw_data list\n",
    "        time.sleep(np.abs(np.random.normal(loc=6,scale=0.5)))  #add sleeper delay to avoid captcha block\n",
    "        print(start, end=' ')  #display how far into the process this loop is (horizontally printed)        \n",
    "\n",
    "    jobtitle_listoflist = []\n",
    "    company_listoflist = []\n",
    "    salary_listoflist = []\n",
    "    location_listoflist = []\n",
    "\n",
    "    for clickcard in raw_data:\n",
    "        jobtitle_listoflist.append(extract_jobtitle_from_result(clickcard)) #collect each clickard element within raw_data \n",
    "        company_listoflist.append(extract_company_from_result(clickcard))\n",
    "        salary_listoflist.append(extract_salary_from_result(clickcard))\n",
    "        location_listoflist.append(extract_location_from_result(clickcard))\n",
    "\n",
    "    jobtitle_list = list(itertools.chain(*jobtitle_listoflist)) #convert list of lists into single list using itertools\n",
    "    company_list = list(itertools.chain(*company_listoflist))\n",
    "    salary_list = list(itertools.chain(*salary_listoflist))\n",
    "    location_list = list(itertools.chain(*location_listoflist))\n",
    "    \n",
    "    #create key value pairs of each city name for its corresponding dataframe after each iteration of city\n",
    "    key = city \n",
    "    value = pd.DataFrame({'jobtitle': jobtitle_list, 'company': company_list, \n",
    "                          'salary': salary_list, 'location': location_list})\n",
    "    dict_of_city_dfs[key] = value #updating dictionary with new dataframe for each city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving to CSV's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_city_dfs['london'].to_csv('london.csv')\n",
    "dict_of_city_dfs['manchester'].to_csv('manchester.csv')\n",
    "dict_of_city_dfs['birmingham'].to_csv('birmingham.csv')\n",
    "dict_of_city_dfs['leeds'].to_csv('leeds.csv')\n",
    "dict_of_city_dfs['glasgow'].to_csv('glasgow.csv')\n",
    "dict_of_city_dfs['southampton'].to_csv('southampton.csv')\n",
    "dict_of_city_dfs['liverpool'].to_csv('liverpool.csv')\n",
    "dict_of_city_dfs['newcastle'].to_csv('newcastle.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
